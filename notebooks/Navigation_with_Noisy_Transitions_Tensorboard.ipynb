{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding tensorboard visualization to MDPs in TensorFlow - Navigation with Noisy Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import abc\n",
    "import functools\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to help cleaning and creating the log and save folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_folder(folder_name):\n",
    "    \"\"\"\n",
    "    Clean the folder 'folder_name'\n",
    "\n",
    "    :type folder_name: str\n",
    "    \"\"\"\n",
    "    currentdir = os.getcwd()\n",
    "    log_path = os.path.join(currentdir, folder_name)\n",
    "    if os.path.exists(log_path):\n",
    "        shutil.rmtree(log_path)\n",
    "\n",
    "\n",
    "def get_time_stamp():\n",
    "    \"\"\"\n",
    "    Time stamp generator e.g. 12-11-2016_18-20-45\n",
    "\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    return time.strftime('%d-%m-%Y_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling MDPs in TensorFlow (as before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All classes defining MDPs must inherit from abstract class ```MDP```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP(metaclass=abc.ABCMeta):\n",
    "    \n",
    "    @abc.abstractproperty\n",
    "    def action_size(self):\n",
    "        return\n",
    "    \n",
    "    @abc.abstractproperty\n",
    "    def state_size(self):\n",
    "        return\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def transition(self, state, action):\n",
    "        return\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def reward(self, state, action):\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New version of the navigation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Navigation(MDP):\n",
    "    \"\"\"\n",
    "    Class that encodes a mnp navigation scenario\n",
    "\n",
    "    :type graph: tf.Graph\n",
    "    :type kwargs: dict\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        with graph.as_default():\n",
    "            with tf.name_scope(\"grid_constants\"):\n",
    "                self._size = tf.constant(self.size, dtype=tf.float32, name=\"size\")\n",
    "                self._center = tf.constant(self.center, dtype=tf.float32)\n",
    "                self._goal = tf.constant(self.goal, dtype=tf.float32)\n",
    "            with tf.name_scope(\"numerical_constants\"):\n",
    "                self._0_00 = tf.constant(0.00, dtype=tf.float32)\n",
    "                self._1_00 = tf.constant(1.00, dtype=tf.float32)\n",
    "                self._2_00 = tf.constant(2.00, dtype=tf.float32)\n",
    "                self._8_00 = tf.constant(8.00, dtype=tf.float32)\n",
    "                self._decay = tf.constant(self.decay, dtype=tf.float32)\n",
    "\n",
    "    @property\n",
    "    def action_size(self):\n",
    "        \"\"\"\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.ndim\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        \"\"\"\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.ndim\n",
    "        \n",
    "    def transition(self, state, action, noise):\n",
    "        \"\"\"\n",
    "        takes one transition step on the mdp\n",
    "\n",
    "        :type stape: tf.Tensor\n",
    "                     shape=(batch_size,\n",
    "                            self.ndim)\n",
    "                     dtype=float32\n",
    "\n",
    "        :type action: tf.Tensor\n",
    "                     shape=(batch_size,\n",
    "                            self.ndim)\n",
    "                     dtype=float32\n",
    "\n",
    "        :type noise: tf.Tensor\n",
    "                     shape=(batch_size, 1)\n",
    "                     dtype=float32\n",
    "\n",
    "        :rtype: tf.Tensor\n",
    "                shape=(batch_size,\n",
    "                       self.ndim)\n",
    "                dtype=float32\n",
    "        \"\"\"\n",
    "\n",
    "        # rotation angle (in degrees)\n",
    "        velocity = tf.norm(action, axis=1, keep_dims=True)\n",
    "        \n",
    "        # f(x) = 1 / (1 + exp(-8(x-1)))\n",
    "        atenuation = self._1_00 / (self._1_00 + tf.exp(-self._8_00 * (velocity - self._1_00)))\n",
    "        max_theta = 20  # degrees\n",
    "        theta =  max_theta * atenuation\n",
    "\n",
    "        # apply rotation noise\n",
    "        cos, sin = tf.cos(theta * np.pi / 180 * noise), tf.sin(theta * np.pi / 180 * noise)\n",
    "        \n",
    "        noise_matrix = tf.stack([cos, -sin, sin, cos], axis=1)\n",
    "        noise_matrix = tf.reshape(noise_matrix, [-1, 2, 2])\n",
    "        noisy_action = tf.matmul(noise_matrix, tf.reshape(action, [-1, 2, 1]))\n",
    "        noisy_action = tf.reshape(noisy_action, [-1, 2])\n",
    "        \n",
    "        # distance to center of grid\n",
    "        d = tf.sqrt(tf.reduce_sum(tf.square(state - self._center), 1, keep_dims=True))\n",
    "\n",
    "        # deceleration_factor\n",
    "        deceleration = self._2_00 / (self._1_00 + tf.exp(-self._decay * d)) - self._1_00\n",
    "        # deceleration = self.__1_00\n",
    "        \n",
    "        # next position\n",
    "        next_state = state + deceleration * noisy_action\n",
    "        next_state = tf.clip_by_value(next_state, self._0_00, self._size)\n",
    "\n",
    "        return next_state\n",
    "\n",
    "    def reward(self, state, action=None):\n",
    "        \"\"\"\n",
    "        calculates the norm L-2 (euclidean distance)\n",
    "        actions are not used\n",
    "\n",
    "        :type stape: tf.Tensor\n",
    "                     shape=(batch_size,\n",
    "                            self.ndim)\n",
    "                     dtype=float32\n",
    "\n",
    "        :type action: None\n",
    "\n",
    "        :rtype: tf.Tensor\n",
    "                shape=(batch_size, 1)\n",
    "                dtype=float32\n",
    "        \"\"\"\n",
    "        return -tf.sqrt(tf.reduce_sum(tf.square(state - self._goal), 1, keep_dims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding an MDP as a Recurrent Neural Net (as before, docstting addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP_RNNCell(tf.nn.rnn_cell.RNNCell):\n",
    "    \"\"\"\n",
    "    MDP as a RNN cell\n",
    "\n",
    "    :type mdp: MDP\n",
    "\n",
    "    :type policy: function\n",
    "                     -input: tf.Tensor\n",
    "                            shape=(batch_size,\n",
    "                                   ndim)\n",
    "                            dtype=float32\n",
    "                     -output: tf.Tensor\n",
    "                            shape=(batch_size,\n",
    "                                   ndim)\n",
    "                            dtype=float32 \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mdp, policy):\n",
    "        self.mdp = mdp\n",
    "        self.policy = policy\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        \"\"\"\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.mdp.state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        \"\"\"\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.mdp.state_size + self.mdp.action_size + 1\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        \"\"\"\n",
    "        Perform the rnn call\n",
    "        \n",
    "        :type input: tf.Tensor\n",
    "                     shape=(batch_size,\n",
    "                            1)\n",
    "                     dtype=float32\n",
    "\n",
    "        :type state: tf.Tensor\n",
    "                     shape=(batch_size,\n",
    "                            mdp.state_size)\n",
    "                     dtype=float32\n",
    "\n",
    "        :rtype output: tf.Tensor\n",
    "                       shape=(batch_size,\n",
    "                              mdp.state_size\n",
    "                              + mdp.action_size\n",
    "                              + 1)\n",
    "                       dtype=float32\n",
    "\n",
    "        :rtype next_state: tf.Tensor\n",
    "                           shape=(batch_size,\n",
    "                                  mdp.state_size)\n",
    "                           dtype=float32\n",
    "        \"\"\"\n",
    "        # add policy network\n",
    "        action = self.policy(state)\n",
    "\n",
    "        # add MDP components to the RNN cell output\n",
    "        noise = inputs\n",
    "        next_state =  self.mdp.transition(state, action, noise)\n",
    "        reward = self.mdp.reward(next_state, action)\n",
    "        output = tf.concat([reward, next_state, action], 1)\n",
    "        \n",
    "        return output, next_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy as a Neural Net (as before, docstting addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_network(layers, state, limits=1.0):\n",
    "    \"\"\"\n",
    "    Neural network to approximate the optimal policy\n",
    "\n",
    "    :type layer: [int]\n",
    "\n",
    "    :type state: tf.Tensor\n",
    "                 shape=(batch_size,\n",
    "                        ndim)\n",
    "                dtype=float32\n",
    "\n",
    "    :rtype: tf.Tensor\n",
    "            shape=(batch_size,\n",
    "                        ndim)\n",
    "                dtype=float32\n",
    "    \"\"\"\n",
    "    assert(layers[0] == state.shape[1])\n",
    "\n",
    "    with tf.variable_scope('policy'):\n",
    "        \n",
    "        # hidden layers\n",
    "        outputs = state\n",
    "        for i, n_h in enumerate(layers[1:]):\n",
    "            if i != len(layers)-2:\n",
    "                activation = tf.nn.relu\n",
    "            else:\n",
    "                activation = tf.nn.tanh\n",
    "\n",
    "            outputs = tf.layers.dense(outputs,\n",
    "                                      units=n_h,\n",
    "                                      activation=activation,\n",
    "                                      kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                      name=\"layer\"+str(i+1))\n",
    "\n",
    "        # add action limits over last tanh layer\n",
    "        action = tf.constant(limits) * outputs\n",
    "\n",
    "    # print(tf.get_default_graph().get_collection('variables'))\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A class to hold all the hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"\n",
    "    Holds model hyperparams.\n",
    "\n",
    "    :type batch_size: int\n",
    "    :type max_time: int\n",
    "    :type epoch: int\n",
    "    :type noise_ratio: float\n",
    "    :type learning_rate: float\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 batch_size=10000,\n",
    "                 max_time=9,\n",
    "                 epoch=100,\n",
    "                 noise_ratio = 1.0,\n",
    "                 learning_rate=0.1):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_time = max_time\n",
    "        self.epoch = epoch\n",
    "        self.noise_ratio = noise_ratio\n",
    "        self.learning_rate = learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A wrapper for the navigation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAV_Wrapper(object):\n",
    "    \"\"\"\n",
    "    Wrapper for the Navigation MDP.\n",
    "    \n",
    "    :type config: Config\n",
    "    :type params: dict\n",
    "    :type policy: funtion\n",
    "    :type name: None or str\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 config,\n",
    "                 policy,\n",
    "                 name=None):\n",
    "        if not os.path.exists(\"models\"):\n",
    "            os.makedirs(\"models\")\n",
    "        if name is not None:\n",
    "            self.log_path = os.path.join('graphs', name)\n",
    "            self.save_path = os.path.join('models', name, 'model.ckpt')\n",
    "        else:\n",
    "            time_stamp = get_time_stamp()\n",
    "            self.log_path = os.path.join('graphs', time_stamp)\n",
    "            self.save_path = os.path.join('models', time_stamp, 'model.ckpt')\n",
    "        self.config = config\n",
    "        self.graph = tf.Graph()\n",
    "        self.mdp = Navigation(self.graph, **params)\n",
    "        self.policy = policy\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "        Build the tensorflow graph\n",
    "        \"\"\"\n",
    "        max_time = self.config.max_time\n",
    "        batch_size = self.config.batch_size\n",
    "        learning_rate = self.config.learning_rate\n",
    "        ndim = self.mdp.ndim\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope(\"grid_constants\"):\n",
    "                x_initial, y_initial = self.mdp.initial\n",
    "                x_initial = tf.fill([batch_size], tf.constant(x_initial, tf.float32))\n",
    "                y_initial = tf.fill([batch_size], tf.constant(y_initial, tf.float32))\n",
    "                initial_state = tf.stack([x_initial, y_initial], axis=1)\n",
    "\n",
    "            with tf.name_scope(\"Noise\"):\n",
    "                self.inputs = tf.placeholder(tf.float32, shape=[None, max_time, 1], name=\"inputs\")\n",
    "\n",
    "            with tf.name_scope(\"RNNCell\"):\n",
    "                cell = MDP_RNNCell(self.mdp, self.policy)\n",
    "                outputs, self.final_state = tf.nn.dynamic_rnn(cell,\n",
    "                                                         self.inputs,\n",
    "                                                         initial_state=initial_state,\n",
    "                                                         dtype=tf.float32)\n",
    "\n",
    "\n",
    "                outputs = tf.unstack(outputs, axis=2)\n",
    "                max_time = int(self.inputs.shape[1])\n",
    "\n",
    "                self.rewards = tf.reshape(outputs[0], [-1, max_time, 1])\n",
    "                self.states  = tf.stack(outputs[1:3], axis=2)\n",
    "                self.actions = tf.stack(outputs[3:5], axis=2)\n",
    "\n",
    "            with tf.name_scope(\"rewards\"):\n",
    "                self.total = tf.reduce_sum(self.rewards, 1)\n",
    "                \n",
    "            with tf.name_scope(\"last_state_summary\"):\n",
    "                last_states = tf.slice(self.states, [0, max_time -1, 0], [-1, -1, -1])\n",
    "                last_states = tf.reshape(last_states, (batch_size, ndim))\n",
    "                best_batch = tf.argmax(self.total,0)\n",
    "                best_last_state = tf.nn.embedding_lookup(last_states, best_batch)\n",
    "                best_last_state = tf.reshape(best_last_state, (ndim, 1))\n",
    "                tf.summary.histogram('last_states_summ', best_last_state)\n",
    "\n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.loss  = tf.reduce_mean(tf.square(self.total))\n",
    "                tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "            with tf.name_scope(\"optimizer\"):\n",
    "                self.train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(self.loss)\n",
    "\n",
    "            with tf.name_scope(\"global_initializer\"):\n",
    "                self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "            with tf.name_scope(\"saver\"):\n",
    "                self.saver = tf.train.Saver()\n",
    "                \n",
    "    def train(self, show_progress=True):\n",
    "        \"\"\"\n",
    "        Train the model, log all the progress in tensorboard\n",
    "        and save the model paramaters in the folder 'self.save_path'\n",
    "\n",
    "        :type show_progress: boolean\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        epoch = self.config.epoch\n",
    "        size = (self.config.batch_size, self.config.max_time, 1)\n",
    "        ratio = self.config.noise_ratio\n",
    "        noise_size = (int(ratio * size[0]), size[1], 1)\n",
    "        with tf.Session(graph=self.graph) as sess:\n",
    "\n",
    "            # writing in tensorboard\n",
    "            summary_writer = tf.summary.FileWriter(self.log_path, sess.graph)\n",
    "            all_summaries = tf.summary.merge_all()\n",
    "\n",
    "            # initialize variables\n",
    "            sess.run(self.init_op)\n",
    "            self.losses = []\n",
    "\n",
    "            for epoch_idx in range(epoch):\n",
    "                # sample noise data from normal distribution\n",
    "                # random_noise = np.random.normal(size=self.noise_size).astype(np.float32)\n",
    "\n",
    "                # sample noise data from uniform distribution\n",
    "                random_noise = np.random.uniform(low=-1.0, high=1.0, size=noise_size).astype(np.float32)\n",
    "\n",
    "                # no noise at all...\n",
    "                shape = (size[0] - noise_size[0], size[1], 1)\n",
    "                zero_noise = np.zeros(shape=shape).astype(np.float32)\n",
    "\n",
    "                # noise\n",
    "                inputs_data = np.concatenate([random_noise, zero_noise], axis=0)\n",
    "\n",
    "                # backprop and update weights\n",
    "                _, loss, summary, total = sess.run([self.train_step,\n",
    "                                                    self.loss,\n",
    "                                                    all_summaries,\n",
    "                                                    self.total],\n",
    "                                                   feed_dict={self.inputs: inputs_data})\n",
    "                # writing the log\n",
    "                summary_writer.add_summary(summary, epoch_idx)\n",
    "                summary_writer.flush()\n",
    "\n",
    "                # store and show loss information\n",
    "                self.losses.append(loss)\n",
    "                if show_progress:\n",
    "                    print('Epoch {0:5}: loss = {1}\\r'.format(epoch_idx, loss), end='')\n",
    "\n",
    "            self.variables = sess.run({ var.name: var for var in tf.trainable_variables() })\n",
    "            self.total_cost_per_batch = total\n",
    "            \n",
    "            # save model\n",
    "            save_path = self.saver.save(sess, self.save_path)\n",
    "            print(\"\\nModel saved in file: %s\" % save_path)\n",
    "            print(\"\\n&&&&&&&&& For TensorBoard visualization type &&&&&&&&&&&\")\n",
    "            print(\"\\ntensorboard  --logdir {}\\n\".format(self.log_path))\n",
    "\n",
    "        end = time.time()\n",
    "        self.uptime = end - start\n",
    "        print(\"Done in {0:.6f} sec\".format(self.uptime))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a training with the wrapper class using the default hyperparams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_folder(\"graphs\")\n",
    "clean_folder(\"models\")\n",
    "\n",
    "mdp_params = {\n",
    "    'ndim': 2,\n",
    "    'size': (10.0, 10.0),\n",
    "    'initial': (1.0, 5.0),\n",
    "    'goal': (8.0, 5.0),\n",
    "    'center': (5.0, 5.0),\n",
    "    'decay': 2.0,\n",
    "    'limits': (-1.0, 1.0)\n",
    "}\n",
    "\n",
    "layers = [2, 20, 5, 2]\n",
    "policy = functools.partial(policy_network, layers)\n",
    "\n",
    "my_config = Config()\n",
    "nav = NAV_Wrapper(mdp_params, my_config, policy)\n",
    "nav.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can run the tensorboard by uncommenting and running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tensorboard  --logdir <folder_name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I tried to add 3 visualizations in Tensorboard\n",
    "\n",
    "\n",
    "### A plot of the loss over the different epochs\n",
    "\n",
    "\n",
    "<img src=\"files/img/loss.png\" width=\"600px\">\n",
    "\n",
    "### The graph of the model\n",
    "\n",
    "<img src=\"files/img/graph.png\" width=\"600px\">\n",
    "\n",
    "### A summary with the final position with the best planner over the different epochs\n",
    "\n",
    "<img src=\"files/img/summary.png\" width=\"600px\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
